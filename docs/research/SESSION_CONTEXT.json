{
  "project": "AlphaZero Light - Connect Four Training",
  "critical_bug_fixed": "Model always trained as Player 1, never learned blocking. Fixed with 50/50 player role randomization.",
  "current_goal": "Train a competent Connect Four agent that learns both offense and defense",
  
  "hardware": {
    "cpu": "Intel i9-14900KF (24 cores/32 threads)",
    "gpu": "NVIDIA RTX 5080 (15.44GB VRAM)",
    "cuda": "12.8",
    "pytorch": "2.9.1+cu128"
  },
  
  "environment": {
    "conda_env": "azl",
    "python": "3.10",
    "activation": "conda activate azl",
    "working_dir": "/home/michael/.gemini/antigravity/scratch/alpha-zero-light"
  },
  
  "training_schedule_optimized": {
    "total_iterations": 200,
    "warmup_phase": {
      "iterations": "0-109 (110 total)",
      "phase_1": "0-19 (20 iter): Pure Random - learn valid moves",
      "phase_2": "20-44 (25 iter): 1-ply Heuristic - basic win/block",
      "phase_3": "45-74 (30 iter): Mixed (30% tactical, 25% aggressive, 25% heuristic, 20% random)",
      "phase_4": "75-109 (35 iter): Strong 2-ply + mixed (30% strong, 20% tactical, 25% aggressive, 25% heuristic)"
    },
    "self_play_phase": {
      "iterations": "110-199 (90 iter)",
      "mix": "80% self-play, 10% aggressive, 10% heuristic"
    },
    "training_params": {
      "epochs_per_iteration": 150,
      "games_per_iteration": 400,
      "batch_size": 512,
      "mcts_searches": 100
    }
  },
  
  "model_architecture": {
    "type": "ResNet",
    "residual_blocks": 10,
    "hidden_units": 128,
    "game": "Connect Four 6x7, win length 4"
  },
  
  "key_scripts": {
    "start_training": "./start_training.sh",
    "monitor_progress": "./monitor_training.sh (in separate terminal)",
    "check_status": "./check_training.sh",
    "pause": "./pause_training.sh",
    "resume": "./resume_training.sh"
  },
  
  "testing": {
    "script": "scripts/test_model_progress.py",
    "schedule": "Tests at iterations 5, 10, 20, 30, 40, 50, etc.",
    "tests": ["find_win", "block_threat", "empty_board_value", "prefer_center"],
    "results_file": "model_test_results.json"
  },
  
  "checkpoints": {
    "location": "checkpoints/connect4/",
    "files": "model_{iteration}.pt, optimizer_{iteration}.pt"
  },
  
  "git_branch": "4inarow",
  
  "latest_changes": {
    "commit": "a470090",
    "message": "Optimize training schedule: extend phase 3 & 4, reduce self-play to 90, increase epochs to 150",
    "files_modified": ["config_connect4.py", "trainer.py"]
  },
  
  "performance": "~6 games/second sequential self-play",
  
  "known_issues": {
    "multiprocessing": "Abandoned due to CUDA/multiprocessing deadlocks",
    "pip_install": "pip install -e . fails with pybind11 error - USE BASH SCRIPTS instead"
  },
  
  "next_action": "Run ./start_training.sh to begin training with optimized schedule"
}
